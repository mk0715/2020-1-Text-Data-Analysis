{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_excel('범죄와의전쟁.xlsx',index_col=0)\n",
    "df2 = pd.read_excel('광해.xlsx',index_col=0)\n",
    "df3 = pd.read_excel('내부자들.xlsx',index_col=0)\n",
    "df4 = pd.read_excel('더킹.xlsx',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nan값 있는 항 모두제거\n",
    "df1 = df1.dropna(axis=0)\n",
    "df2 = df2.dropna(axis=0)\n",
    "df3 = df3.dropna(axis=0)\n",
    "df4 = df4.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nsmc1.txt', 'w', encoding='utf8') as f:  \n",
    "    f.write('\\n'.join(df1['review']))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentencepiece import SentencePieceTrainer\n",
    "SentencePieceTrainer.Train('--input=nsmc1.txt --model_prefix=nsmc1 --vocab_size=3000') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentencepiece import SentencePieceProcessor\n",
    "sp1 = SentencePieceProcessor()\n",
    "sp1.Load(\"nsmc1.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv1 = CountVectorizer(lowercase=False, tokenizer=sp1.encode_as_pieces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdm1 = cv1.fit_transform(df1['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = tdm1\n",
    "y1 = df1['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train, x1_test, y1_train, y1_test = train_test_split(x1, y1, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv1.tokenizer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nsmc1.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump((cv1,x1_train,x1_test,y1_train,y1_test), 'nsmc1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1463, 3038)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.add(\n",
    "    tf.keras.layers.Dense(\n",
    "        1, \n",
    "        input_shape=(3038,),\n",
    "        activation='sigmoid', \n",
    "        kernel_regularizer=tf.keras.regularizers.l2(0.001) \n",
    "    ))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1)                 3039      \n",
      "=================================================================\n",
      "Total params: 3,039\n",
      "Trainable params: 3,039\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1316 samples, validate on 147 samples\n",
      "Epoch 1/100\n",
      "1316/1316 [==============================] - 0s 232us/sample - loss: 0.6142 - accuracy: 0.7758 - val_loss: 0.4971 - val_accuracy: 0.9456\n",
      "Epoch 2/100\n",
      "1316/1316 [==============================] - 0s 39us/sample - loss: 0.5161 - accuracy: 0.8708 - val_loss: 0.4260 - val_accuracy: 0.9456\n",
      "Epoch 3/100\n",
      "1316/1316 [==============================] - 0s 36us/sample - loss: 0.4757 - accuracy: 0.8701 - val_loss: 0.3949 - val_accuracy: 0.9456\n",
      "Epoch 4/100\n",
      "1316/1316 [==============================] - 0s 35us/sample - loss: 0.4491 - accuracy: 0.8701 - val_loss: 0.3731 - val_accuracy: 0.9456\n",
      "Epoch 5/100\n",
      "1316/1316 [==============================] - 0s 36us/sample - loss: 0.4271 - accuracy: 0.8708 - val_loss: 0.3605 - val_accuracy: 0.9456\n",
      "Epoch 6/100\n",
      "1316/1316 [==============================] - 0s 35us/sample - loss: 0.4081 - accuracy: 0.8708 - val_loss: 0.3512 - val_accuracy: 0.9456\n",
      "Epoch 7/100\n",
      "1316/1316 [==============================] - 0s 36us/sample - loss: 0.3911 - accuracy: 0.8723 - val_loss: 0.3405 - val_accuracy: 0.9456\n",
      "Epoch 8/100\n",
      "1316/1316 [==============================] - 0s 36us/sample - loss: 0.3757 - accuracy: 0.8739 - val_loss: 0.3363 - val_accuracy: 0.9456\n",
      "Epoch 9/100\n",
      "1316/1316 [==============================] - 0s 33us/sample - loss: 0.3614 - accuracy: 0.8746 - val_loss: 0.3292 - val_accuracy: 0.9456\n",
      "Epoch 10/100\n",
      "1316/1316 [==============================] - 0s 35us/sample - loss: 0.3490 - accuracy: 0.8754 - val_loss: 0.3233 - val_accuracy: 0.9456\n",
      "Epoch 11/100\n",
      "1316/1316 [==============================] - 0s 34us/sample - loss: 0.3378 - accuracy: 0.8761 - val_loss: 0.3183 - val_accuracy: 0.9456\n",
      "Epoch 12/100\n",
      "1316/1316 [==============================] - 0s 33us/sample - loss: 0.3277 - accuracy: 0.8815 - val_loss: 0.3148 - val_accuracy: 0.9456\n",
      "Epoch 13/100\n",
      "1316/1316 [==============================] - 0s 34us/sample - loss: 0.3183 - accuracy: 0.8906 - val_loss: 0.3118 - val_accuracy: 0.9456\n",
      "Epoch 14/100\n",
      "1316/1316 [==============================] - ETA: 0s - loss: 0.2316 - accuracy: 0.96 - 0s 34us/sample - loss: 0.3104 - accuracy: 0.8921 - val_loss: 0.3075 - val_accuracy: 0.9456\n",
      "Epoch 15/100\n",
      "1316/1316 [==============================] - 0s 34us/sample - loss: 0.3027 - accuracy: 0.8989 - val_loss: 0.3063 - val_accuracy: 0.9456\n",
      "Epoch 16/100\n",
      "1316/1316 [==============================] - 0s 33us/sample - loss: 0.2958 - accuracy: 0.9035 - val_loss: 0.3028 - val_accuracy: 0.9456\n",
      "Epoch 17/100\n",
      "1316/1316 [==============================] - 0s 34us/sample - loss: 0.2896 - accuracy: 0.9050 - val_loss: 0.2996 - val_accuracy: 0.9456\n",
      "Epoch 18/100\n",
      "1316/1316 [==============================] - 0s 33us/sample - loss: 0.2841 - accuracy: 0.9119 - val_loss: 0.2989 - val_accuracy: 0.9456\n",
      "Epoch 19/100\n",
      "1316/1316 [==============================] - 0s 34us/sample - loss: 0.2790 - accuracy: 0.9149 - val_loss: 0.2955 - val_accuracy: 0.9456\n",
      "Epoch 20/100\n",
      "1316/1316 [==============================] - 0s 34us/sample - loss: 0.2742 - accuracy: 0.9202 - val_loss: 0.2955 - val_accuracy: 0.9456\n",
      "Epoch 21/100\n",
      "1316/1316 [==============================] - 0s 33us/sample - loss: 0.2698 - accuracy: 0.9217 - val_loss: 0.2925 - val_accuracy: 0.9456\n",
      "Epoch 22/100\n",
      "1316/1316 [==============================] - 0s 35us/sample - loss: 0.2659 - accuracy: 0.9263 - val_loss: 0.2911 - val_accuracy: 0.9456\n",
      "Epoch 23/100\n",
      "1316/1316 [==============================] - 0s 33us/sample - loss: 0.2620 - accuracy: 0.9309 - val_loss: 0.2915 - val_accuracy: 0.9456\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19a780e0c48>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(x1_train.toarray(), y1_train, epochs=100, validation_split=0.1,\n",
    "         callbacks=[tf.keras.callbacks.EarlyStopping()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "366/366 [==============================] - 0s 44us/sample - loss: 0.3559 - accuracy: 0.9071\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3558588099609959, 0.90710384]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(x1_test.toarray(), y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights1,_ = model1.trainable_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_weight1 = pd.DataFrame({'토큰': cv1.get_feature_names(), '가중치': weights1.numpy().flat})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>토큰</th>\n",
       "      <th>가중치</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>T</td>\n",
       "      <td>-0.318324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2609</th>\n",
       "      <td>조선</td>\n",
       "      <td>-0.303892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>▁별로</td>\n",
       "      <td>-0.268537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>V</td>\n",
       "      <td>-0.267715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>▁재미없</td>\n",
       "      <td>-0.255375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        토큰       가중치\n",
       "73       T -0.318324\n",
       "2609    조선 -0.303892\n",
       "634    ▁별로 -0.268537\n",
       "74       V -0.267715\n",
       "1139  ▁재미없 -0.255375"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_weight1.sort_values('가중치').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>토큰</th>\n",
       "      <th>가중치</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>▁최고</td>\n",
       "      <td>0.375433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>▁연기</td>\n",
       "      <td>0.379698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1151</th>\n",
       "      <td>▁재밌게</td>\n",
       "      <td>0.381203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!!</td>\n",
       "      <td>0.392650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>▁살아있네</td>\n",
       "      <td>0.440150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         토큰       가중치\n",
       "1294    ▁최고  0.375433\n",
       "950     ▁연기  0.379698\n",
       "1151   ▁재밌게  0.381203\n",
       "1        !!  0.392650\n",
       "738   ▁살아있네  0.440150"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_weight1.sort_values('가중치').tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nsmc2.txt', 'w', encoding='utf8') as f:  \n",
    "    f.write('\\n'.join(df2['review']))  \n",
    "\n",
    "SentencePieceTrainer.Train('--input=nsmc2.txt --model_prefix=nsmc2 --vocab_size=3000')  # 총 어휘수 3000개\n",
    "\n",
    "sp2 = SentencePieceProcessor()\n",
    "sp2.Load(\"nsmc2.model\")\n",
    "\n",
    "\n",
    "cv2 = CountVectorizer(lowercase=False, tokenizer=sp2.encode_as_pieces)\n",
    "\n",
    "tdm2 = cv2.fit_transform(df2['review'])\n",
    "\n",
    "x2 = tdm2\n",
    "y2 = df2['sentiment']\n",
    "\n",
    "x2_train, x2_test, y2_train, y2_test = train_test_split(x2, y2, test_size=0.2, random_state=42)\n",
    "\n",
    "cv2.tokenizer = None\n",
    "\n",
    "joblib.dump((cv2,x2_train,x2_test,y2_train,y2_test), 'nsmc2.pkl')\n",
    "\n",
    "model2 = tf.keras.models.Sequential()\n",
    "\n",
    "model2.add(\n",
    "    tf.keras.layers.Dense(\n",
    "        1, \n",
    "        input_shape=(3077,),\n",
    "        activation='sigmoid', \n",
    "        kernel_regularizer=tf.keras.regularizers.l2(0.001) \n",
    "    ))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1)                 3078      \n",
      "=================================================================\n",
      "Total params: 3,078\n",
      "Trainable params: 3,078\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2466 samples, validate on 275 samples\n",
      "Epoch 1/100\n",
      "2466/2466 [==============================] - 0s 116us/sample - loss: 0.5609 - accuracy: 0.8447 - val_loss: 0.4602 - val_accuracy: 0.9164\n",
      "Epoch 2/100\n",
      "2466/2466 [==============================] - 0s 35us/sample - loss: 0.4357 - accuracy: 0.9075 - val_loss: 0.4054 - val_accuracy: 0.9164\n",
      "Epoch 3/100\n",
      "2466/2466 [==============================] - 0s 36us/sample - loss: 0.3917 - accuracy: 0.9075 - val_loss: 0.3779 - val_accuracy: 0.9164\n",
      "Epoch 4/100\n",
      "2466/2466 [==============================] - 0s 36us/sample - loss: 0.3626 - accuracy: 0.9079 - val_loss: 0.3599 - val_accuracy: 0.9164\n",
      "Epoch 5/100\n",
      "2466/2466 [==============================] - 0s 34us/sample - loss: 0.3389 - accuracy: 0.9084 - val_loss: 0.3453 - val_accuracy: 0.9164\n",
      "Epoch 6/100\n",
      "2466/2466 [==============================] - 0s 35us/sample - loss: 0.3188 - accuracy: 0.9092 - val_loss: 0.3334 - val_accuracy: 0.9164\n",
      "Epoch 7/100\n",
      "2466/2466 [==============================] - 0s 34us/sample - loss: 0.3019 - accuracy: 0.9100 - val_loss: 0.3239 - val_accuracy: 0.9164\n",
      "Epoch 8/100\n",
      "2466/2466 [==============================] - 0s 35us/sample - loss: 0.2877 - accuracy: 0.9108 - val_loss: 0.3163 - val_accuracy: 0.9164\n",
      "Epoch 9/100\n",
      "2466/2466 [==============================] - 0s 34us/sample - loss: 0.2757 - accuracy: 0.9120 - val_loss: 0.3094 - val_accuracy: 0.9164\n",
      "Epoch 10/100\n",
      "2466/2466 [==============================] - 0s 35us/sample - loss: 0.2656 - accuracy: 0.9144 - val_loss: 0.3037 - val_accuracy: 0.9164\n",
      "Epoch 11/100\n",
      "2466/2466 [==============================] - 0s 34us/sample - loss: 0.2570 - accuracy: 0.9161 - val_loss: 0.2991 - val_accuracy: 0.9164\n",
      "Epoch 12/100\n",
      "2466/2466 [==============================] - 0s 34us/sample - loss: 0.2497 - accuracy: 0.9173 - val_loss: 0.2953 - val_accuracy: 0.9164\n",
      "Epoch 13/100\n",
      "2466/2466 [==============================] - 0s 34us/sample - loss: 0.2435 - accuracy: 0.9193 - val_loss: 0.2920 - val_accuracy: 0.9164\n",
      "Epoch 14/100\n",
      "2466/2466 [==============================] - 0s 34us/sample - loss: 0.2378 - accuracy: 0.9238 - val_loss: 0.2890 - val_accuracy: 0.9164\n",
      "Epoch 15/100\n",
      "2466/2466 [==============================] - 0s 34us/sample - loss: 0.2330 - accuracy: 0.9262 - val_loss: 0.2867 - val_accuracy: 0.9164\n",
      "Epoch 16/100\n",
      "2466/2466 [==============================] - 0s 34us/sample - loss: 0.2287 - accuracy: 0.9294 - val_loss: 0.2844 - val_accuracy: 0.9164\n",
      "Epoch 17/100\n",
      "2466/2466 [==============================] - 0s 34us/sample - loss: 0.2249 - accuracy: 0.9323 - val_loss: 0.2824 - val_accuracy: 0.9164\n",
      "Epoch 18/100\n",
      "2466/2466 [==============================] - 0s 33us/sample - loss: 0.2215 - accuracy: 0.9343 - val_loss: 0.2804 - val_accuracy: 0.9164\n",
      "Epoch 19/100\n",
      "2466/2466 [==============================] - 0s 33us/sample - loss: 0.2184 - accuracy: 0.9355 - val_loss: 0.2790 - val_accuracy: 0.9164\n",
      "Epoch 20/100\n",
      "2466/2466 [==============================] - 0s 32us/sample - loss: 0.2157 - accuracy: 0.9363 - val_loss: 0.2778 - val_accuracy: 0.9164\n",
      "Epoch 21/100\n",
      "2466/2466 [==============================] - 0s 33us/sample - loss: 0.2131 - accuracy: 0.9376 - val_loss: 0.2768 - val_accuracy: 0.9164\n",
      "Epoch 22/100\n",
      "2466/2466 [==============================] - 0s 32us/sample - loss: 0.2109 - accuracy: 0.9380 - val_loss: 0.2756 - val_accuracy: 0.9200\n",
      "Epoch 23/100\n",
      "2466/2466 [==============================] - 0s 32us/sample - loss: 0.2089 - accuracy: 0.9388 - val_loss: 0.2747 - val_accuracy: 0.9200\n",
      "Epoch 24/100\n",
      "2466/2466 [==============================] - 0s 32us/sample - loss: 0.2071 - accuracy: 0.9408 - val_loss: 0.2741 - val_accuracy: 0.9200\n",
      "Epoch 25/100\n",
      "2466/2466 [==============================] - 0s 32us/sample - loss: 0.2053 - accuracy: 0.9412 - val_loss: 0.2727 - val_accuracy: 0.9200\n",
      "Epoch 26/100\n",
      "2466/2466 [==============================] - 0s 32us/sample - loss: 0.2036 - accuracy: 0.9424 - val_loss: 0.2718 - val_accuracy: 0.9200\n",
      "Epoch 27/100\n",
      "2466/2466 [==============================] - 0s 32us/sample - loss: 0.2022 - accuracy: 0.9416 - val_loss: 0.2714 - val_accuracy: 0.9200\n",
      "Epoch 28/100\n",
      "2466/2466 [==============================] - 0s 32us/sample - loss: 0.2009 - accuracy: 0.9420 - val_loss: 0.2705 - val_accuracy: 0.9200\n",
      "Epoch 29/100\n",
      "2466/2466 [==============================] - 0s 32us/sample - loss: 0.1998 - accuracy: 0.9440 - val_loss: 0.2693 - val_accuracy: 0.9200\n",
      "Epoch 30/100\n",
      "2466/2466 [==============================] - 0s 33us/sample - loss: 0.1986 - accuracy: 0.9461 - val_loss: 0.2694 - val_accuracy: 0.9200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19a79749588>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) \n",
    "\n",
    "model2.fit(x2_train.toarray(), y2_train, epochs=100, validation_split=0.1,\n",
    "         callbacks=[tf.keras.callbacks.EarlyStopping()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "686/686 [==============================] - 0s 25us/sample - loss: 0.2832 - accuracy: 0.9155\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.28324324335718293, 0.9154519]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(x2_test.toarray(), y2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>토큰</th>\n",
       "      <th>가중치</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1694</th>\n",
       "      <td>냐</td>\n",
       "      <td>-0.508830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>▁데이브</td>\n",
       "      <td>-0.464805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>▁이게</td>\n",
       "      <td>-0.447141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>▁표절</td>\n",
       "      <td>-0.355221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>▁알바들</td>\n",
       "      <td>-0.348203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        토큰       가중치\n",
       "1694     냐 -0.508830\n",
       "443   ▁데이브 -0.464805\n",
       "1049   ▁이게 -0.447141\n",
       "1377   ▁표절 -0.355221\n",
       "854   ▁알바들 -0.348203"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights2,_ = model2.trainable_weights\n",
    "\n",
    "token_weight2 = pd.DataFrame({'토큰': cv2.get_feature_names(), '가중치': weights2.numpy().flat})\n",
    "\n",
    "token_weight2.sort_values('가중치').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>토큰</th>\n",
       "      <th>가중치</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>▁이병헌의</td>\n",
       "      <td>0.531894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>▁최고</td>\n",
       "      <td>0.531994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!</td>\n",
       "      <td>0.567077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129</th>\n",
       "      <td>▁잘</td>\n",
       "      <td>0.578303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>▁연기</td>\n",
       "      <td>0.591277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         토큰       가중치\n",
       "1066  ▁이병헌의  0.531894\n",
       "1329    ▁최고  0.531994\n",
       "0         !  0.567077\n",
       "1129     ▁잘  0.578303\n",
       "915     ▁연기  0.591277"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_weight2.sort_values('가중치').tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nsmc3.txt', 'w', encoding='utf8') as f:  \n",
    "    f.write('\\n'.join(df3['review']))  \n",
    "\n",
    "SentencePieceTrainer.Train('--input=nsmc3.txt --model_prefix=nsmc3 --vocab_size=3000')  # 총 어휘수 3000개\n",
    "\n",
    "sp3 = SentencePieceProcessor()\n",
    "sp3.Load(\"nsmc3.model\")\n",
    "\n",
    "\n",
    "cv3 = CountVectorizer(lowercase=False, tokenizer=sp3.encode_as_pieces)\n",
    "\n",
    "tdm3 = cv3.fit_transform(df3['review'])\n",
    "\n",
    "x3 = tdm3\n",
    "y3 = df3['sentiment']\n",
    "\n",
    "x3_train, x3_test, y3_train, y3_test = train_test_split(x3, y3, test_size=0.2, random_state=43)\n",
    "\n",
    "cv3.tokenizer = None\n",
    "\n",
    "joblib.dump((cv3,x3_train,x3_test,y3_train,y3_test), 'nsmc3.pkl')\n",
    "\n",
    "model3 = tf.keras.models.Sequential()\n",
    "\n",
    "model3.add(\n",
    "    tf.keras.layers.Dense(\n",
    "        1, \n",
    "        input_shape=(2976,),\n",
    "        activation='sigmoid', \n",
    "        kernel_regularizer=tf.keras.regularizers.l2(0.001)   \n",
    "    ))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 1)                 2977      \n",
      "=================================================================\n",
      "Total params: 2,977\n",
      "Trainable params: 2,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 709 samples, validate on 79 samples\n",
      "Epoch 1/100\n",
      "709/709 [==============================] - 0s 307us/sample - loss: 0.6214 - accuracy: 0.7983 - val_loss: 0.5621 - val_accuracy: 0.9114\n",
      "Epoch 2/100\n",
      "709/709 [==============================] - 0s 54us/sample - loss: 0.5120 - accuracy: 0.9323 - val_loss: 0.4987 - val_accuracy: 0.9494\n",
      "Epoch 3/100\n",
      "709/709 [==============================] - 0s 40us/sample - loss: 0.4494 - accuracy: 0.9394 - val_loss: 0.4621 - val_accuracy: 0.9494\n",
      "Epoch 4/100\n",
      "709/709 [==============================] - 0s 40us/sample - loss: 0.4112 - accuracy: 0.9394 - val_loss: 0.4375 - val_accuracy: 0.9494\n",
      "Epoch 5/100\n",
      "709/709 [==============================] - 0s 41us/sample - loss: 0.3833 - accuracy: 0.9394 - val_loss: 0.4207 - val_accuracy: 0.9494\n",
      "Epoch 6/100\n",
      "709/709 [==============================] - 0s 38us/sample - loss: 0.3625 - accuracy: 0.9394 - val_loss: 0.4083 - val_accuracy: 0.9494\n",
      "Epoch 7/100\n",
      "709/709 [==============================] - 0s 37us/sample - loss: 0.3457 - accuracy: 0.9394 - val_loss: 0.3974 - val_accuracy: 0.9494\n",
      "Epoch 8/100\n",
      "709/709 [==============================] - 0s 37us/sample - loss: 0.3311 - accuracy: 0.9394 - val_loss: 0.3889 - val_accuracy: 0.9494\n",
      "Epoch 9/100\n",
      "709/709 [==============================] - 0s 38us/sample - loss: 0.3189 - accuracy: 0.9394 - val_loss: 0.3817 - val_accuracy: 0.9494\n",
      "Epoch 10/100\n",
      "709/709 [==============================] - 0s 38us/sample - loss: 0.3078 - accuracy: 0.9394 - val_loss: 0.3751 - val_accuracy: 0.9494\n",
      "Epoch 11/100\n",
      "709/709 [==============================] - 0s 38us/sample - loss: 0.2980 - accuracy: 0.9394 - val_loss: 0.3698 - val_accuracy: 0.9494\n",
      "Epoch 12/100\n",
      "709/709 [==============================] - 0s 37us/sample - loss: 0.2893 - accuracy: 0.9394 - val_loss: 0.3643 - val_accuracy: 0.9494\n",
      "Epoch 13/100\n",
      "709/709 [==============================] - 0s 37us/sample - loss: 0.2810 - accuracy: 0.9394 - val_loss: 0.3594 - val_accuracy: 0.9494\n",
      "Epoch 14/100\n",
      "709/709 [==============================] - 0s 37us/sample - loss: 0.2737 - accuracy: 0.9408 - val_loss: 0.3551 - val_accuracy: 0.9494\n",
      "Epoch 15/100\n",
      "709/709 [==============================] - 0s 38us/sample - loss: 0.2664 - accuracy: 0.9408 - val_loss: 0.3511 - val_accuracy: 0.9494\n",
      "Epoch 16/100\n",
      "709/709 [==============================] - 0s 38us/sample - loss: 0.2598 - accuracy: 0.9408 - val_loss: 0.3471 - val_accuracy: 0.9494\n",
      "Epoch 17/100\n",
      "709/709 [==============================] - 0s 37us/sample - loss: 0.2536 - accuracy: 0.9408 - val_loss: 0.3438 - val_accuracy: 0.9494\n",
      "Epoch 18/100\n",
      "709/709 [==============================] - 0s 37us/sample - loss: 0.2479 - accuracy: 0.9408 - val_loss: 0.3399 - val_accuracy: 0.9494\n",
      "Epoch 19/100\n",
      "709/709 [==============================] - 0s 38us/sample - loss: 0.2424 - accuracy: 0.9408 - val_loss: 0.3369 - val_accuracy: 0.9494\n",
      "Epoch 20/100\n",
      "709/709 [==============================] - 0s 35us/sample - loss: 0.2375 - accuracy: 0.9408 - val_loss: 0.3340 - val_accuracy: 0.9494\n",
      "Epoch 21/100\n",
      "709/709 [==============================] - 0s 37us/sample - loss: 0.2325 - accuracy: 0.9408 - val_loss: 0.3313 - val_accuracy: 0.9494\n",
      "Epoch 22/100\n",
      "709/709 [==============================] - 0s 38us/sample - loss: 0.2279 - accuracy: 0.9408 - val_loss: 0.3285 - val_accuracy: 0.9494\n",
      "Epoch 23/100\n",
      "709/709 [==============================] - 0s 37us/sample - loss: 0.2235 - accuracy: 0.9422 - val_loss: 0.3258 - val_accuracy: 0.9494\n",
      "Epoch 24/100\n",
      "709/709 [==============================] - 0s 37us/sample - loss: 0.2194 - accuracy: 0.9422 - val_loss: 0.3234 - val_accuracy: 0.9494\n",
      "Epoch 25/100\n",
      "709/709 [==============================] - 0s 38us/sample - loss: 0.2156 - accuracy: 0.9436 - val_loss: 0.3210 - val_accuracy: 0.9494\n",
      "Epoch 26/100\n",
      "709/709 [==============================] - 0s 37us/sample - loss: 0.2120 - accuracy: 0.9450 - val_loss: 0.3186 - val_accuracy: 0.9494\n",
      "Epoch 27/100\n",
      "709/709 [==============================] - 0s 38us/sample - loss: 0.2085 - accuracy: 0.9450 - val_loss: 0.3163 - val_accuracy: 0.9494\n",
      "Epoch 28/100\n",
      "709/709 [==============================] - 0s 38us/sample - loss: 0.2052 - accuracy: 0.9464 - val_loss: 0.3142 - val_accuracy: 0.9494\n",
      "Epoch 29/100\n",
      "709/709 [==============================] - 0s 37us/sample - loss: 0.2022 - accuracy: 0.9464 - val_loss: 0.3121 - val_accuracy: 0.9494\n",
      "Epoch 30/100\n",
      "709/709 [==============================] - 0s 37us/sample - loss: 0.1993 - accuracy: 0.9492 - val_loss: 0.3103 - val_accuracy: 0.9494\n",
      "Epoch 31/100\n",
      "709/709 [==============================] - 0s 37us/sample - loss: 0.1966 - accuracy: 0.9492 - val_loss: 0.3086 - val_accuracy: 0.9494\n",
      "Epoch 32/100\n",
      "709/709 [==============================] - 0s 37us/sample - loss: 0.1939 - accuracy: 0.9506 - val_loss: 0.3070 - val_accuracy: 0.9494\n",
      "Epoch 33/100\n",
      "709/709 [==============================] - 0s 38us/sample - loss: 0.1914 - accuracy: 0.9563 - val_loss: 0.3052 - val_accuracy: 0.9494\n",
      "Epoch 34/100\n",
      "709/709 [==============================] - 0s 35us/sample - loss: 0.1889 - accuracy: 0.9563 - val_loss: 0.3038 - val_accuracy: 0.9494\n",
      "Epoch 35/100\n",
      "709/709 [==============================] - 0s 38us/sample - loss: 0.1866 - accuracy: 0.9563 - val_loss: 0.3020 - val_accuracy: 0.9494\n",
      "Epoch 36/100\n",
      "709/709 [==============================] - 0s 38us/sample - loss: 0.1845 - accuracy: 0.9563 - val_loss: 0.3004 - val_accuracy: 0.9494\n",
      "Epoch 37/100\n",
      "709/709 [==============================] - 0s 35us/sample - loss: 0.1823 - accuracy: 0.9563 - val_loss: 0.2991 - val_accuracy: 0.9494\n",
      "Epoch 38/100\n",
      "709/709 [==============================] - 0s 38us/sample - loss: 0.1803 - accuracy: 0.9577 - val_loss: 0.2975 - val_accuracy: 0.9494\n",
      "Epoch 39/100\n",
      "709/709 [==============================] - 0s 38us/sample - loss: 0.1784 - accuracy: 0.9591 - val_loss: 0.2966 - val_accuracy: 0.9494\n",
      "Epoch 40/100\n",
      "709/709 [==============================] - 0s 37us/sample - loss: 0.1766 - accuracy: 0.9591 - val_loss: 0.2951 - val_accuracy: 0.9494\n",
      "Epoch 41/100\n",
      "709/709 [==============================] - 0s 38us/sample - loss: 0.1749 - accuracy: 0.9591 - val_loss: 0.2940 - val_accuracy: 0.9494\n",
      "Epoch 42/100\n",
      "709/709 [==============================] - 0s 38us/sample - loss: 0.1732 - accuracy: 0.9591 - val_loss: 0.2929 - val_accuracy: 0.9494\n",
      "Epoch 43/100\n",
      "709/709 [==============================] - 0s 37us/sample - loss: 0.1716 - accuracy: 0.9605 - val_loss: 0.2915 - val_accuracy: 0.9494\n",
      "Epoch 44/100\n",
      "709/709 [==============================] - 0s 37us/sample - loss: 0.1700 - accuracy: 0.9605 - val_loss: 0.2901 - val_accuracy: 0.9494\n",
      "Epoch 45/100\n",
      "709/709 [==============================] - 0s 38us/sample - loss: 0.1685 - accuracy: 0.9605 - val_loss: 0.2890 - val_accuracy: 0.9494\n",
      "Epoch 46/100\n",
      "709/709 [==============================] - 0s 37us/sample - loss: 0.1672 - accuracy: 0.9633 - val_loss: 0.2878 - val_accuracy: 0.9494\n",
      "Epoch 47/100\n",
      "709/709 [==============================] - 0s 38us/sample - loss: 0.1656 - accuracy: 0.9633 - val_loss: 0.2859 - val_accuracy: 0.9494\n",
      "Epoch 48/100\n",
      "709/709 [==============================] - 0s 38us/sample - loss: 0.1643 - accuracy: 0.9633 - val_loss: 0.2852 - val_accuracy: 0.9494\n",
      "Epoch 49/100\n",
      "709/709 [==============================] - 0s 38us/sample - loss: 0.1630 - accuracy: 0.9661 - val_loss: 0.2845 - val_accuracy: 0.9494\n",
      "Epoch 50/100\n",
      "709/709 [==============================] - 0s 37us/sample - loss: 0.1617 - accuracy: 0.9661 - val_loss: 0.2836 - val_accuracy: 0.9494\n",
      "Epoch 51/100\n",
      "709/709 [==============================] - 0s 38us/sample - loss: 0.1606 - accuracy: 0.9690 - val_loss: 0.2827 - val_accuracy: 0.9494\n",
      "Epoch 52/100\n",
      "709/709 [==============================] - 0s 38us/sample - loss: 0.1595 - accuracy: 0.9690 - val_loss: 0.2820 - val_accuracy: 0.9494\n",
      "Epoch 53/100\n",
      "709/709 [==============================] - 0s 37us/sample - loss: 0.1584 - accuracy: 0.9690 - val_loss: 0.2810 - val_accuracy: 0.9494\n",
      "Epoch 54/100\n",
      "709/709 [==============================] - 0s 37us/sample - loss: 0.1574 - accuracy: 0.9690 - val_loss: 0.2804 - val_accuracy: 0.9494\n",
      "Epoch 55/100\n",
      "709/709 [==============================] - 0s 38us/sample - loss: 0.1563 - accuracy: 0.9690 - val_loss: 0.2794 - val_accuracy: 0.9494\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "709/709 [==============================] - 0s 37us/sample - loss: 0.1553 - accuracy: 0.9690 - val_loss: 0.2784 - val_accuracy: 0.9494\n",
      "Epoch 57/100\n",
      "709/709 [==============================] - 0s 38us/sample - loss: 0.1545 - accuracy: 0.9690 - val_loss: 0.2778 - val_accuracy: 0.9494\n",
      "Epoch 58/100\n",
      "709/709 [==============================] - 0s 37us/sample - loss: 0.1534 - accuracy: 0.9690 - val_loss: 0.2766 - val_accuracy: 0.9494\n",
      "Epoch 59/100\n",
      "709/709 [==============================] - 0s 37us/sample - loss: 0.1525 - accuracy: 0.9690 - val_loss: 0.2756 - val_accuracy: 0.9494\n",
      "Epoch 60/100\n",
      "709/709 [==============================] - 0s 38us/sample - loss: 0.1517 - accuracy: 0.9704 - val_loss: 0.2744 - val_accuracy: 0.9494\n",
      "Epoch 61/100\n",
      "709/709 [==============================] - 0s 37us/sample - loss: 0.1508 - accuracy: 0.9690 - val_loss: 0.2737 - val_accuracy: 0.9494\n",
      "Epoch 62/100\n",
      "709/709 [==============================] - 0s 37us/sample - loss: 0.1499 - accuracy: 0.9704 - val_loss: 0.2729 - val_accuracy: 0.9494\n",
      "Epoch 63/100\n",
      "709/709 [==============================] - 0s 37us/sample - loss: 0.1492 - accuracy: 0.9704 - val_loss: 0.2723 - val_accuracy: 0.9494\n",
      "Epoch 64/100\n",
      "709/709 [==============================] - 0s 37us/sample - loss: 0.1484 - accuracy: 0.9732 - val_loss: 0.2709 - val_accuracy: 0.9494\n",
      "Epoch 65/100\n",
      "709/709 [==============================] - 0s 37us/sample - loss: 0.1476 - accuracy: 0.9732 - val_loss: 0.2704 - val_accuracy: 0.9494\n",
      "Epoch 66/100\n",
      "709/709 [==============================] - 0s 37us/sample - loss: 0.1468 - accuracy: 0.9746 - val_loss: 0.2695 - val_accuracy: 0.9494\n",
      "Epoch 67/100\n",
      "709/709 [==============================] - 0s 37us/sample - loss: 0.1461 - accuracy: 0.9746 - val_loss: 0.2690 - val_accuracy: 0.9494\n",
      "Epoch 68/100\n",
      "709/709 [==============================] - 0s 38us/sample - loss: 0.1454 - accuracy: 0.9746 - val_loss: 0.2681 - val_accuracy: 0.9494\n",
      "Epoch 69/100\n",
      "709/709 [==============================] - 0s 38us/sample - loss: 0.1447 - accuracy: 0.9760 - val_loss: 0.2677 - val_accuracy: 0.9494\n",
      "Epoch 70/100\n",
      "709/709 [==============================] - 0s 38us/sample - loss: 0.1440 - accuracy: 0.9760 - val_loss: 0.2669 - val_accuracy: 0.9494\n",
      "Epoch 71/100\n",
      "709/709 [==============================] - 0s 38us/sample - loss: 0.1434 - accuracy: 0.9774 - val_loss: 0.2660 - val_accuracy: 0.9494\n",
      "Epoch 72/100\n",
      "709/709 [==============================] - 0s 35us/sample - loss: 0.1427 - accuracy: 0.9760 - val_loss: 0.2653 - val_accuracy: 0.9494\n",
      "Epoch 73/100\n",
      "709/709 [==============================] - 0s 38us/sample - loss: 0.1421 - accuracy: 0.9760 - val_loss: 0.2645 - val_accuracy: 0.9494\n",
      "Epoch 74/100\n",
      "709/709 [==============================] - 0s 35us/sample - loss: 0.1415 - accuracy: 0.9774 - val_loss: 0.2636 - val_accuracy: 0.9494\n",
      "Epoch 75/100\n",
      "709/709 [==============================] - 0s 37us/sample - loss: 0.1409 - accuracy: 0.9774 - val_loss: 0.2633 - val_accuracy: 0.9494\n",
      "Epoch 76/100\n",
      "709/709 [==============================] - 0s 37us/sample - loss: 0.1403 - accuracy: 0.9774 - val_loss: 0.2625 - val_accuracy: 0.9494\n",
      "Epoch 77/100\n",
      "709/709 [==============================] - 0s 35us/sample - loss: 0.1397 - accuracy: 0.9774 - val_loss: 0.2615 - val_accuracy: 0.9494\n",
      "Epoch 78/100\n",
      "709/709 [==============================] - 0s 37us/sample - loss: 0.1392 - accuracy: 0.9774 - val_loss: 0.2606 - val_accuracy: 0.9494\n",
      "Epoch 79/100\n",
      "709/709 [==============================] - 0s 38us/sample - loss: 0.1386 - accuracy: 0.9774 - val_loss: 0.2601 - val_accuracy: 0.9494\n",
      "Epoch 80/100\n",
      "709/709 [==============================] - 0s 37us/sample - loss: 0.1381 - accuracy: 0.9774 - val_loss: 0.2597 - val_accuracy: 0.9494\n",
      "Epoch 81/100\n",
      "709/709 [==============================] - 0s 37us/sample - loss: 0.1376 - accuracy: 0.9774 - val_loss: 0.2586 - val_accuracy: 0.9494\n",
      "Epoch 82/100\n",
      "709/709 [==============================] - 0s 38us/sample - loss: 0.1371 - accuracy: 0.9774 - val_loss: 0.2577 - val_accuracy: 0.9494\n",
      "Epoch 83/100\n",
      "709/709 [==============================] - 0s 38us/sample - loss: 0.1365 - accuracy: 0.9774 - val_loss: 0.2571 - val_accuracy: 0.9494\n",
      "Epoch 84/100\n",
      "709/709 [==============================] - 0s 37us/sample - loss: 0.1361 - accuracy: 0.9774 - val_loss: 0.2566 - val_accuracy: 0.9494\n",
      "Epoch 85/100\n",
      "709/709 [==============================] - 0s 35us/sample - loss: 0.1356 - accuracy: 0.9774 - val_loss: 0.2560 - val_accuracy: 0.9494\n",
      "Epoch 86/100\n",
      "709/709 [==============================] - 0s 37us/sample - loss: 0.1351 - accuracy: 0.9774 - val_loss: 0.2555 - val_accuracy: 0.9494\n",
      "Epoch 87/100\n",
      "709/709 [==============================] - 0s 37us/sample - loss: 0.1346 - accuracy: 0.9788 - val_loss: 0.2548 - val_accuracy: 0.9494\n",
      "Epoch 88/100\n",
      "709/709 [==============================] - 0s 37us/sample - loss: 0.1342 - accuracy: 0.9788 - val_loss: 0.2541 - val_accuracy: 0.9494\n",
      "Epoch 89/100\n",
      "709/709 [==============================] - 0s 35us/sample - loss: 0.1337 - accuracy: 0.9788 - val_loss: 0.2531 - val_accuracy: 0.9494\n",
      "Epoch 90/100\n",
      "709/709 [==============================] - 0s 35us/sample - loss: 0.1333 - accuracy: 0.9788 - val_loss: 0.2521 - val_accuracy: 0.9494\n",
      "Epoch 91/100\n",
      "709/709 [==============================] - 0s 38us/sample - loss: 0.1329 - accuracy: 0.9803 - val_loss: 0.2509 - val_accuracy: 0.9494\n",
      "Epoch 92/100\n",
      "709/709 [==============================] - 0s 35us/sample - loss: 0.1324 - accuracy: 0.9803 - val_loss: 0.2505 - val_accuracy: 0.9494\n",
      "Epoch 93/100\n",
      "709/709 [==============================] - 0s 37us/sample - loss: 0.1320 - accuracy: 0.9803 - val_loss: 0.2498 - val_accuracy: 0.9494\n",
      "Epoch 94/100\n",
      "709/709 [==============================] - 0s 37us/sample - loss: 0.1316 - accuracy: 0.9803 - val_loss: 0.2493 - val_accuracy: 0.9494\n",
      "Epoch 95/100\n",
      "709/709 [==============================] - 0s 37us/sample - loss: 0.1312 - accuracy: 0.9803 - val_loss: 0.2488 - val_accuracy: 0.9494\n",
      "Epoch 96/100\n",
      "709/709 [==============================] - 0s 38us/sample - loss: 0.1309 - accuracy: 0.9803 - val_loss: 0.2476 - val_accuracy: 0.9494\n",
      "Epoch 97/100\n",
      "709/709 [==============================] - 0s 37us/sample - loss: 0.1305 - accuracy: 0.9803 - val_loss: 0.2474 - val_accuracy: 0.9494\n",
      "Epoch 98/100\n",
      "709/709 [==============================] - 0s 35us/sample - loss: 0.1301 - accuracy: 0.9803 - val_loss: 0.2464 - val_accuracy: 0.9494\n",
      "Epoch 99/100\n",
      "709/709 [==============================] - 0s 35us/sample - loss: 0.1297 - accuracy: 0.9803 - val_loss: 0.2456 - val_accuracy: 0.9494\n",
      "Epoch 100/100\n",
      "709/709 [==============================] - 0s 38us/sample - loss: 0.1293 - accuracy: 0.9803 - val_loss: 0.2448 - val_accuracy: 0.9494\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19a79743848>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) \n",
    "\n",
    "model3.fit(x3_train.toarray(), y3_train, epochs=100, validation_split=0.1,\n",
    "         callbacks=[tf.keras.callbacks.EarlyStopping()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197/197 [==============================] - 0s 36us/sample - loss: 0.1884 - accuracy: 0.9695\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1883635123822895, 0.96954316]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.evaluate(x3_test.toarray(), y3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>토큰</th>\n",
       "      <th>가중치</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>▁무슨</td>\n",
       "      <td>-0.490435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783</th>\n",
       "      <td>내용인지</td>\n",
       "      <td>-0.473362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>▁재미없</td>\n",
       "      <td>-0.427505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2900</th>\n",
       "      <td>해서</td>\n",
       "      <td>-0.406046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>▁대</td>\n",
       "      <td>-0.381082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        토큰       가중치\n",
       "577    ▁무슨 -0.490435\n",
       "1783  내용인지 -0.473362\n",
       "1210  ▁재미없 -0.427505\n",
       "2900    해서 -0.406046\n",
       "398     ▁대 -0.381082"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights3,_ = model3.trainable_weights\n",
    "\n",
    "token_weight3 = pd.DataFrame({'토큰': cv3.get_feature_names(), '가중치': weights3.numpy().flat})\n",
    "\n",
    "token_weight3.sort_values('가중치').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>토큰</th>\n",
       "      <th>가중치</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>~~</td>\n",
       "      <td>0.543954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>▁3</td>\n",
       "      <td>0.551459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!</td>\n",
       "      <td>0.576938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1392</th>\n",
       "      <td>▁최고</td>\n",
       "      <td>0.729540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>▁굿</td>\n",
       "      <td>0.749861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       토큰       가중치\n",
       "90     ~~  0.543954\n",
       "134    ▁3  0.551459\n",
       "0       !  0.576938\n",
       "1392  ▁최고  0.729540\n",
       "248    ▁굿  0.749861"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_weight3.sort_values('가중치').tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nsmc4.txt', 'w', encoding='utf8') as f:  \n",
    "    f.write('\\n'.join(df4['review']))  \n",
    "\n",
    "SentencePieceTrainer.Train('--input=nsmc4.txt --model_prefix=nsmc4 --vocab_size=3000')  # 총 어휘수 3000개\n",
    "\n",
    "sp4 = SentencePieceProcessor()\n",
    "sp4.Load(\"nsmc4.model\")\n",
    "\n",
    "\n",
    "cv4 = CountVectorizer(lowercase=False, tokenizer=sp4.encode_as_pieces)\n",
    "\n",
    "tdm4 = cv4.fit_transform(df4['review'])\n",
    "\n",
    "x4 = tdm4\n",
    "y4 = df4['sentiment']\n",
    "\n",
    "x4_train, x4_test, y4_train, y4_test = train_test_split(x4, y4, test_size=0.2, random_state=44)\n",
    "\n",
    "cv4.tokenizer = None\n",
    "\n",
    "joblib.dump((cv4,x4_train,x4_test,y4_train,y4_test), 'nsmc4.pkl')\n",
    "\n",
    "model4 = tf.keras.models.Sequential()\n",
    "\n",
    "x4_train.shape\n",
    "\n",
    "model4.add(\n",
    "    tf.keras.layers.Dense(\n",
    "        1, \n",
    "        input_shape=(3045,),\n",
    "        activation='sigmoid', \n",
    "        kernel_regularizer=tf.keras.regularizers.l2(0.001)  \n",
    "    ))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 1)                 3046      \n",
      "=================================================================\n",
      "Total params: 3,046\n",
      "Trainable params: 3,046\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1833 samples, validate on 204 samples\n",
      "Epoch 1/100\n",
      "1833/1833 [==============================] - 0s 141us/sample - loss: 0.6286 - accuracy: 0.7943 - val_loss: 0.6106 - val_accuracy: 0.8235\n",
      "Epoch 2/100\n",
      "1833/1833 [==============================] - 0s 32us/sample - loss: 0.5646 - accuracy: 0.8358 - val_loss: 0.5866 - val_accuracy: 0.8235\n",
      "Epoch 3/100\n",
      "1833/1833 [==============================] - 0s 32us/sample - loss: 0.5267 - accuracy: 0.8347 - val_loss: 0.5690 - val_accuracy: 0.8235\n",
      "Epoch 4/100\n",
      "1833/1833 [==============================] - 0s 34us/sample - loss: 0.4954 - accuracy: 0.8352 - val_loss: 0.5533 - val_accuracy: 0.8235\n",
      "Epoch 5/100\n",
      "1833/1833 [==============================] - 0s 32us/sample - loss: 0.4678 - accuracy: 0.8363 - val_loss: 0.5394 - val_accuracy: 0.8235\n",
      "Epoch 6/100\n",
      "1833/1833 [==============================] - 0s 34us/sample - loss: 0.4440 - accuracy: 0.8396 - val_loss: 0.5266 - val_accuracy: 0.8235\n",
      "Epoch 7/100\n",
      "1833/1833 [==============================] - 0s 32us/sample - loss: 0.4233 - accuracy: 0.8445 - val_loss: 0.5172 - val_accuracy: 0.8235\n",
      "Epoch 8/100\n",
      "1833/1833 [==============================] - 0s 32us/sample - loss: 0.4058 - accuracy: 0.8587 - val_loss: 0.5087 - val_accuracy: 0.8235\n",
      "Epoch 9/100\n",
      "1833/1833 [==============================] - 0s 29us/sample - loss: 0.3900 - accuracy: 0.8680 - val_loss: 0.5016 - val_accuracy: 0.8235\n",
      "Epoch 10/100\n",
      "1833/1833 [==============================] - 0s 39us/sample - loss: 0.3764 - accuracy: 0.8745 - val_loss: 0.4949 - val_accuracy: 0.8235\n",
      "Epoch 11/100\n",
      "1833/1833 [==============================] - 0s 32us/sample - loss: 0.3647 - accuracy: 0.8849 - val_loss: 0.4896 - val_accuracy: 0.8235\n",
      "Epoch 12/100\n",
      "1833/1833 [==============================] - 0s 33us/sample - loss: 0.3544 - accuracy: 0.8914 - val_loss: 0.4855 - val_accuracy: 0.8284\n",
      "Epoch 13/100\n",
      "1833/1833 [==============================] - 0s 31us/sample - loss: 0.3452 - accuracy: 0.8931 - val_loss: 0.4822 - val_accuracy: 0.8284\n",
      "Epoch 14/100\n",
      "1833/1833 [==============================] - 0s 34us/sample - loss: 0.3370 - accuracy: 0.8996 - val_loss: 0.4788 - val_accuracy: 0.8235\n",
      "Epoch 15/100\n",
      "1833/1833 [==============================] - 0s 33us/sample - loss: 0.3298 - accuracy: 0.9034 - val_loss: 0.4755 - val_accuracy: 0.8284\n",
      "Epoch 16/100\n",
      "1833/1833 [==============================] - 0s 34us/sample - loss: 0.3233 - accuracy: 0.9062 - val_loss: 0.4740 - val_accuracy: 0.8333\n",
      "Epoch 17/100\n",
      "1833/1833 [==============================] - 0s 35us/sample - loss: 0.3175 - accuracy: 0.9116 - val_loss: 0.4717 - val_accuracy: 0.8333\n",
      "Epoch 18/100\n",
      "1833/1833 [==============================] - 0s 32us/sample - loss: 0.3123 - accuracy: 0.9116 - val_loss: 0.4705 - val_accuracy: 0.8284\n",
      "Epoch 19/100\n",
      "1833/1833 [==============================] - 0s 31us/sample - loss: 0.3077 - accuracy: 0.9149 - val_loss: 0.4686 - val_accuracy: 0.8284\n",
      "Epoch 20/100\n",
      "1833/1833 [==============================] - 0s 38us/sample - loss: 0.3033 - accuracy: 0.9160 - val_loss: 0.4683 - val_accuracy: 0.8284\n",
      "Epoch 21/100\n",
      "1833/1833 [==============================] - 0s 32us/sample - loss: 0.2994 - accuracy: 0.9176 - val_loss: 0.4663 - val_accuracy: 0.8284\n",
      "Epoch 22/100\n",
      "1833/1833 [==============================] - 0s 31us/sample - loss: 0.2958 - accuracy: 0.9182 - val_loss: 0.4656 - val_accuracy: 0.8284\n",
      "Epoch 23/100\n",
      "1833/1833 [==============================] - 0s 34us/sample - loss: 0.2925 - accuracy: 0.9220 - val_loss: 0.4642 - val_accuracy: 0.8333\n",
      "Epoch 24/100\n",
      "1833/1833 [==============================] - 0s 33us/sample - loss: 0.2895 - accuracy: 0.9231 - val_loss: 0.4638 - val_accuracy: 0.8333\n",
      "Epoch 25/100\n",
      "1833/1833 [==============================] - 0s 32us/sample - loss: 0.2867 - accuracy: 0.9242 - val_loss: 0.4633 - val_accuracy: 0.8333\n",
      "Epoch 26/100\n",
      "1833/1833 [==============================] - 0s 32us/sample - loss: 0.2843 - accuracy: 0.9242 - val_loss: 0.4636 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19a7b7f3988>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) \n",
    "\n",
    "model4.fit(x4_train.toarray(), y4_train, epochs=100, validation_split=0.1,\n",
    "         callbacks=[tf.keras.callbacks.EarlyStopping()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510/510 [==============================] - 0s 29us/sample - loss: 0.4031 - accuracy: 0.8490\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.40314812905648173, 0.8490196]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.evaluate(x4_test.toarray(), y4_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>토큰</th>\n",
       "      <th>가중치</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1365</th>\n",
       "      <td>▁지루하고</td>\n",
       "      <td>-0.438611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>▁못</td>\n",
       "      <td>-0.427968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1404</th>\n",
       "      <td>▁최악의</td>\n",
       "      <td>-0.391649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>▁실망</td>\n",
       "      <td>-0.362776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>▁나레이션</td>\n",
       "      <td>-0.347984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         토큰       가중치\n",
       "1365  ▁지루하고 -0.438611\n",
       "606      ▁못 -0.427968\n",
       "1404   ▁최악의 -0.391649\n",
       "870     ▁실망 -0.362776\n",
       "367   ▁나레이션 -0.347984"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights4,_ = model4.trainable_weights\n",
    "\n",
    "token_weight4 = pd.DataFrame({'토큰': cv4.get_feature_names(), '가중치': weights4.numpy().flat})\n",
    "\n",
    "token_weight4.sort_values('가중치').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>토큰</th>\n",
       "      <th>가중치</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>▁잘</td>\n",
       "      <td>0.505837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507</th>\n",
       "      <td>▁현실</td>\n",
       "      <td>0.507013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>^^</td>\n",
       "      <td>0.543683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243</th>\n",
       "      <td>▁재밌게</td>\n",
       "      <td>0.562631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>▁꼭</td>\n",
       "      <td>0.597373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        토큰       가중치\n",
       "1202    ▁잘  0.505837\n",
       "1507   ▁현실  0.507013\n",
       "69      ^^  0.543683\n",
       "1243  ▁재밌게  0.562631\n",
       "355     ▁꼭  0.597373"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_weight4.sort_values('가중치').tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 네이버 에서 best 댓글 10개씩을 추출하여 새로운 데이터로 적용시켜봄."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import lxml.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = requests.get('https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=82540&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "root1 = lxml.html.fromstring(res1.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data1 = []\n",
    "for review in root1.cssselect('.score_reple p'):\n",
    "    text = review.text_content().strip()\n",
    "    new_data1.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv1.tokenizer = sp1.encode_as_pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_new = cv1.transform(new_data1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.95040005],\n",
       "       [0.70022285],\n",
       "       [0.7016349 ],\n",
       "       [0.67459166],\n",
       "       [0.9607522 ],\n",
       "       [0.84816766],\n",
       "       [0.76829845],\n",
       "       [0.74512774],\n",
       "       [0.8576355 ],\n",
       "       [0.73191404]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.predict(x1_new.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 상위 10개의 베스트 댓글 분석 결과 대부분이 긍정 반응으로 나타남."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8044546 ],\n",
       "       [0.96871567],\n",
       "       [0.92740744],\n",
       "       [0.9713144 ],\n",
       "       [0.9750368 ],\n",
       "       [0.9583796 ],\n",
       "       [0.8792013 ],\n",
       "       [0.79396695],\n",
       "       [0.9498907 ],\n",
       "       [0.8677815 ]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2 = requests.get('https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=83893&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false')\n",
    "root2 = lxml.html.fromstring(res2.text)\n",
    "    \n",
    "new_data2 = []\n",
    "for review in root2.cssselect('.score_reple p'):\n",
    "    text = review.text_content().strip()\n",
    "    new_data2.append(text)\n",
    "\n",
    "cv2.tokenizer = sp2.encode_as_pieces\n",
    "x2_new = cv2.transform(new_data2)\n",
    "model2.predict(x2_new.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 상위 10개의 베스트 댓글 분석 결과 대부분이 긍정 반응으로 나타남."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.86940473],\n",
       "       [0.9292755 ],\n",
       "       [0.9042327 ],\n",
       "       [0.993309  ],\n",
       "       [0.8398019 ],\n",
       "       [0.8648984 ],\n",
       "       [0.9436459 ],\n",
       "       [0.9948738 ],\n",
       "       [0.9672263 ],\n",
       "       [0.9522758 ]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res3 = requests.get('https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=121788&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false')\n",
    "root3 = lxml.html.fromstring(res3.text)\n",
    "    \n",
    "new_data3 = []\n",
    "for review in root3.cssselect('.score_reple p'):\n",
    "    text = review.text_content().strip()\n",
    "    new_data3.append(text)\n",
    "\n",
    "cv3.tokenizer = sp3.encode_as_pieces\n",
    "x3_new = cv3.transform(new_data3)\n",
    "model3.predict(x3_new.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 상위 10개의 베스트 댓글 분석 결과 대부분이 긍정 반응으로 나타남."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6073537],\n",
       "       [0.8728601],\n",
       "       [0.8398966],\n",
       "       [0.9098527],\n",
       "       [0.878911 ],\n",
       "       [0.9556842],\n",
       "       [0.8199466],\n",
       "       [0.9635894],\n",
       "       [0.9390126],\n",
       "       [0.9537958]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res4 = requests.get('https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=144314&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false')\n",
    "root4 = lxml.html.fromstring(res4.text)\n",
    "    \n",
    "new_data4 = []\n",
    "for review in root4.cssselect('.score_reple p'):\n",
    "    text = review.text_content().strip()\n",
    "    new_data4.append(text)\n",
    "\n",
    "cv4.tokenizer = sp4.encode_as_pieces\n",
    "x4_new = cv4.transform(new_data4)\n",
    "model4.predict(x4_new.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 상위 10개의 베스트 댓글 분석 결과 대부분이 긍정 반응으로 나타남."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
